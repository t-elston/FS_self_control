{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single_neuron_processing\n",
    "Assesses neuron by neuron data for each recording and then saves into summary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from matplotlib_venn import venn3\n",
    "import matplotlib.colors as mcolors\n",
    "import warnings\n",
    "import pingouin as pg\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import glob\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\", message=\"Mean of empty slice\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_labelled_posteriors(indata, labels):\n",
    "\n",
    "    '''\n",
    "    INPUTS:\n",
    "    indata = posterior probabilites from a classifier with the shape\n",
    "            n_trials x n_timesteps x n_classes\n",
    "        \n",
    "    labels = 1d array with len(n_trials) - these labels ought\n",
    "            to correspond to class numbers (layers in indata)\n",
    "\n",
    "    OUTPUT:\n",
    "        labelled_posteriors = posterior probabilities associated with the\n",
    "        classes in the labels input for each timestep and trial\n",
    "    '''\n",
    "\n",
    "    n_trials, n_times, n_classes = indata.shape\n",
    "    class_lbls = np.unique(labels)\n",
    "    class_lbls = class_lbls[~np.isnan(class_lbls)]\n",
    "\n",
    "    # initialize output\n",
    "    labelled_posteriors = np.zeros(shape = (n_trials, n_times))\n",
    "\n",
    "    for ix, lbl in enumerate(class_lbls):\n",
    "        \n",
    "        # find trials where this label was chosen\n",
    "        labelled_posteriors[labels == lbl,:] = indata[labels == lbl,:,int(ix)]\n",
    "        \n",
    "    return labelled_posteriors\n",
    "\n",
    "\n",
    "def pull_balanced_train_set(trials2balance, params2balance):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    trials2balance   - ***logical array*** of the trials you want to balance\n",
    "    params2balance   - ***list*** where each element is a vector of categorical\n",
    "                        parameters to balance (e.g. choice value and side)\n",
    "                        each element of params2balance must have the same\n",
    "                        number of elements as trials2balance\n",
    "    OUTPUTS:\n",
    "    train_ix         - trial indices of a fully balanced training set\n",
    "    leftover_ix      - trial indices of trials not included in train_ix\n",
    "    '''\n",
    "\n",
    "    # Find the indices where trials are selected to balance\n",
    "    balance_indices = np.where(trials2balance)[0]\n",
    "\n",
    "    # Create an array of parameters to balance\n",
    "    params_array = np.array(params2balance).T\n",
    "\n",
    "    # Find unique combinations and their counts\n",
    "    p_combos, p_counts = np.unique(params_array[balance_indices], axis=0, return_counts=True)\n",
    "\n",
    "    # Determine the minimum count for a balanced set\n",
    "    n_to_keep = np.min(p_counts)\n",
    "\n",
    "    # Initialize arrays to mark selected and leftover trials\n",
    "    train_ix = np.zeros(len(trials2balance), dtype=bool)\n",
    "    leftover_ix = np.zeros(len(trials2balance), dtype=bool)\n",
    "\n",
    "    # Select a balanced number of trials for each unique parameter combination\n",
    "    for combo in p_combos:\n",
    "        # Find indices of trials corresponding to the current combination\n",
    "        combo_indices = np.where((params_array == combo).all(axis=1) & trials2balance)[0]\n",
    "\n",
    "        # Shuffle the indices\n",
    "        np.random.shuffle(combo_indices)\n",
    "\n",
    "        # Select n_to_keep trials and mark them as part of the training set\n",
    "        train_ix[combo_indices[:n_to_keep]] = True\n",
    "\n",
    "        # Mark the remaining trials as leftovers\n",
    "        leftover_ix[combo_indices[n_to_keep:]] = True\n",
    "\n",
    "    return train_ix, leftover_ix\n",
    "\n",
    "\n",
    "def random_prop_of_array(inarray, proportion):\n",
    "    '''\n",
    "    INPUTS\n",
    "    inarray = logical/boolean array of indices to potentially use later\n",
    "    proportion = how much of inarray should randomly be selected\n",
    "\n",
    "    OUTPUT\n",
    "    out_array = logical/boolean that's set as 'true' for a proportion of the \n",
    "                initial 'true' values in inarray\n",
    "    '''\n",
    "\n",
    "    out_array = np.zeros(shape = (len(inarray), ))\n",
    "\n",
    "    # find where inarray is true and shuffle those indices\n",
    "    shuffled_ixs = np.random.permutation(np.asarray(np.where(inarray)).flatten())\n",
    "\n",
    "    # keep only a proportion of that array\n",
    "    kept_ix = shuffled_ixs[0: round(len(shuffled_ixs)*proportion)]\n",
    "\n",
    "    # fill in the kept indices\n",
    "    out_array[kept_ix] = 1\n",
    "\n",
    "    # make this a logical/boolean\n",
    "    out_array = out_array > 0\n",
    "\n",
    "    return out_array\n",
    "\n",
    "\n",
    "def pull_from_h5(file_path, data_to_extract):\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            # Check if the data_to_extract exists in the HDF5 file\n",
    "            if data_to_extract in file:\n",
    "                data = file[data_to_extract][...]  # Extract the data\n",
    "                return data\n",
    "            else:\n",
    "                print(f\"'{data_to_extract}' not found in the file.\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    \n",
    "def list_hdf5_data(file_path):\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            print(f\"Datasets in '{file_path}':\")\n",
    "            for dataset in file:\n",
    "                print(dataset)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "def get_ch_and_unch_vals(bhv):\n",
    "    \"\"\"\n",
    "    Extracts chosen (ch_val) and unchosen (unch_val) values associated with each trial.\n",
    "\n",
    "    Parameters:\n",
    "    - bhv (DataFrame): DataFrame behavioral data.\n",
    "\n",
    "    Returns:\n",
    "    - ch_val (ndarray): Array of chosen values for each trial.\n",
    "    - unch_val (ndarray): Array of unchosen values for each trial. \n",
    "                          - places 0s for unchosen values on forced choice trials\n",
    "    \"\"\"\n",
    "    ch_val = np.zeros(shape=(len(bhv, )))\n",
    "    unch_val = np.zeros(shape=(len(bhv, )))\n",
    "\n",
    "    bhv['r_val'] = bhv['r_val'].fillna(0)\n",
    "    bhv['l_val'] = bhv['l_val'].fillna(0)\n",
    "\n",
    "    ch_left = bhv['side'] == -1\n",
    "    ch_right = bhv['side'] == 1\n",
    "\n",
    "    ch_val[ch_left] = bhv['l_val'].loc[ch_left].astype(int)\n",
    "    ch_val[ch_right] = bhv['r_val'].loc[ch_right].astype(int)\n",
    "\n",
    "    unch_val[ch_left] = bhv['r_val'].loc[ch_left].astype(int)\n",
    "    unch_val[ch_right] = bhv['l_val'].loc[ch_right].astype(int)\n",
    "\n",
    "    return ch_val, unch_val\n",
    "\n",
    "\n",
    "def get_ch_and_unch_pps(in_pp, bhv, ch_val, unch_val):\n",
    "    \"\"\"Gets the posteriors associated with the chosen and unchosen classes\n",
    "\n",
    "    Args:\n",
    "        in_pp (ndarray): array of posteriors (n_trials x n_times x n_classes)\n",
    "        bhv (dataframe): details of each trial\n",
    "        ch_val (ndarray): vector indicating the class that is ultimately chosen\n",
    "        unch_val (ndarray): vector indicating the class that was ultimately not chosen\n",
    "\n",
    "    Returns:\n",
    "        ch_pp (ndarray): vector of the postior at each point in time for each trial's chosen option\n",
    "        unch_pp (ndarray): vector of the postior at each point in time for each trial's unchosen option\n",
    "    \"\"\"\n",
    "\n",
    "    # select the chosen and unchosen values \n",
    "    n_trials, n_times, n_classes = np.shape(in_pp)\n",
    "    ch_pp = np.zeros(shape=(n_trials, n_times))\n",
    "    unch_pp = np.zeros(shape=(n_trials, n_times))\n",
    "\n",
    "    # loop over each trial\n",
    "    for t in range(n_trials):\n",
    "        \n",
    "        # get the chosen and unchosen PPs\n",
    "        ch_pp[t, :] = in_pp[t, :, int(ch_val[t]-1)]\n",
    "        unch_pp[t, :] = in_pp[t, :, int(unch_val[t]-1)]\n",
    "        \n",
    "    # set the forced choice unchosen pps to nans, since there was only 1 option\n",
    "    unch_pp[bhv['forced'] == 1, :] = np.nan\n",
    "    \n",
    "    return ch_pp, unch_pp\n",
    "\n",
    "\n",
    "def get_alt_ch_and_unch_pps(in_pp, bhv, s_ch_val, s_unch_val):\n",
    "    \"\"\"Gets the posteriors associated with the chosen and unchosen classes\n",
    "\n",
    "    Args:\n",
    "        in_pp (ndarray): array of posteriors (n_trials x n_times x n_classes)\n",
    "        bhv (dataframe): details of each trial\n",
    "        s_ch_val (ndarray): vector indicating the class that is ultimately chosen\n",
    "        s_unch_val (ndarray): vector indicating the class that was ultimately not chosen\n",
    "\n",
    "    Returns:\n",
    "        alt_ch_pp (ndarray): vector of the postior at each point in time for the alternative value in the other state\n",
    "        alt_unch_pp (ndarray): vector of the postior at each point in time for the alternative value in the other state\n",
    "    \"\"\"\n",
    "\n",
    "    # select the chosen and unchosen values \n",
    "    n_trials, n_times, n_classes = np.shape(in_pp)\n",
    "    alt_ch_pp = np.zeros(shape=(n_trials, n_times))\n",
    "    alt_unch_pp = np.zeros(shape=(n_trials, n_times))\n",
    "\n",
    "    alt_ch_val = np.zeros_like(s_ch_val)\n",
    "    alt_unch_val = np.zeros_like(s_unch_val)\n",
    "    \n",
    "    alt_ch_val[bhv['state'] == 1] = 8 - s_ch_val[bhv['state'] == 1] + 1\n",
    "    alt_ch_val[bhv['state'] == 2] = 8 - s_ch_val[bhv['state'] == 2] + 1\n",
    "\n",
    "    alt_unch_val[bhv['state'] == 1] = 8 - s_unch_val[bhv['state'] == 1] + 1\n",
    "    alt_unch_val[bhv['state'] == 2] = 8 - s_unch_val[bhv['state'] == 2] + 1\n",
    "\n",
    "    for t in range(n_trials):\n",
    "        \n",
    "        alt_ch_pp[t, :] = in_pp[t, :, int(alt_ch_val[t]-1)]\n",
    "        alt_unch_pp[t, :] = in_pp[t, :, int(alt_unch_val[t]-1)]\n",
    "\n",
    "    # set the alternative values to nans for state 3, since there were no alternatives\n",
    "    alt_ch_pp[bhv['state'] == 3] = np.nan\n",
    "    alt_unch_pp[bhv['state'] == 3] = np.nan\n",
    "\n",
    "    return alt_ch_pp, alt_unch_pp\n",
    "\n",
    "def find_candidate_states(indata, n_classes, temporal_thresh, mag_thresh):\n",
    "    \"\"\"Finds periods where decoded posteriors are twice their noise level.\n",
    "\n",
    "    Args:\n",
    "        indata (ndarray): 2d array of posterior probabilities associated with some decoder output.\n",
    "        n_classes (int): How many classes were used in the decoder?\n",
    "        temporal_thresh (int): Number of contiguous samples that must be above a threshold to be a real state (typically 2).\n",
    "        mag_thresh (flat): how many times the noise level must a state be? (e.g. 2 = twice the noise level)\n",
    "\n",
    "    Returns:\n",
    "        state_details (ndarray): 2d array where each row details when a state occurred [trial_num, time_in_trial, state_length].\n",
    "        state_array (ndarray): 2d array the same size as indata. It contains 1 in all locations where there were states and 0s everywhere else.\n",
    "    \"\"\"\n",
    "    state_details = np.array([])\n",
    "    state_array = np.zeros_like(indata)\n",
    "    \n",
    "    state_magnitude_thresh = (1 / n_classes) * mag_thresh\n",
    "\n",
    "    for t in range(indata.shape[0]):\n",
    "        state_len, state_pos, state_type = find_1dsequences(indata[t, :] > state_magnitude_thresh)\n",
    "        state_len = state_len[state_type == True]\n",
    "        state_pos = state_pos[state_type == True]\n",
    "\n",
    "        for i in range(len(state_len)):\n",
    "            state_details = np.concatenate((state_details, np.array([t, state_pos[i], state_len[i]])))\n",
    "\n",
    "    state_details = state_details.reshape(-1, 3)\n",
    "    state_details = state_details[state_details[:, 2] > temporal_thresh, :]\n",
    "\n",
    "    # Update state_array using state_details information\n",
    "    for j in range(len(state_details)):\n",
    "        state_trial, state_start, state_len = state_details[j].astype(int)\n",
    "        state_array[state_trial, state_start:(state_start + state_len)] = 1\n",
    "\n",
    "    return state_details, state_array\n",
    "\n",
    "def moving_average(x, w, axis=0):\n",
    "    '''\n",
    "    Moving average function that operates along specified dimensions of a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray): Input array.\n",
    "    - w (int): Size of the window to convolve the array with (i.e., smoothness factor).\n",
    "    - axis (int): Axis along which to perform the moving average (default is 0).\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Smoothed array along the specified axis with the same size as the input array.\n",
    "    '''\n",
    "    x = np.asarray(x)  # Ensure input is a NumPy array\n",
    "    if np.isnan(x).any():\n",
    "        x = np.nan_to_num(x)  # Replace NaN values with zeros\n",
    "\n",
    "    if axis < 0:\n",
    "        axis += x.ndim  # Adjust negative axis value\n",
    "\n",
    "    kernel = np.ones(w) / w  # Create kernel for moving average\n",
    "\n",
    "    # Pad the array before applying convolution\n",
    "    pad_width = [(0, 0)] * x.ndim  # Initialize padding for each axis\n",
    "    pad_width[axis] = (w - 1, 0)  # Pad along the specified axis (left side)\n",
    "    x_padded = np.pad(x, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "    # Apply 1D convolution along the specified axis on the padded array\n",
    "    return np.apply_along_axis(lambda m: np.convolve(m, kernel, mode='valid'), axis, x_padded)\n",
    "\n",
    "def find_1dsequences(inarray):\n",
    "        ''' \n",
    "        run length encoding. Partial credit to R rle function. \n",
    "        Multi datatype arrays catered for including non Numpy\n",
    "        returns: tuple (runlengths, startpositions, values) \n",
    "        '''\n",
    "        ia = np.asarray(inarray)                # force numpy\n",
    "        n = len(ia)\n",
    "        if n == 0: \n",
    "            return (None, None, None)\n",
    "        else:\n",
    "            y = ia[1:] != ia[:-1]                 # pairwise unequal (string safe)\n",
    "            i = np.append(np.where(y), n - 1)     # must include last element \n",
    "            lens = np.diff(np.append(-1, i))      # run lengths\n",
    "            pos = np.cumsum(np.append(0, lens))[:-1] # positions\n",
    "            return(lens, pos, ia[i])\n",
    "        \n",
    "        \n",
    "def calculate_mean_and_interval(data, type='sem', num_samples=1000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculate mean and either SEM or bootstrapped CI for each column of the input array, disregarding NaN values.\n",
    "\n",
    "    Parameters:\n",
    "    - data: 2D numpy array\n",
    "    - type: str, either 'sem' or 'bootstrap_ci'\n",
    "    - num_samples: int, number of bootstrap samples (applicable only for type='bootstrap_ci')\n",
    "    - alpha: float, significance level for the confidence interval (applicable only for type='bootstrap_ci')\n",
    "\n",
    "    Returns:\n",
    "    - means: 1D numpy array containing means for each column\n",
    "    - interval: 1D numpy array containing SEMs or bootstrapped CIs for each column\n",
    "    \"\"\"\n",
    "    nan_mask = ~np.isnan(data)\n",
    "    \n",
    "    nanmean_result = np.nanmean(data, axis=0)\n",
    "    n_valid_values = np.sum(nan_mask, axis=0)\n",
    "    \n",
    "    if type == 'sem':\n",
    "        nanstd_result = np.nanstd(data, axis=0)\n",
    "        interval = nanstd_result / np.sqrt(n_valid_values)\n",
    "        \n",
    "    elif type == 'percentile':\n",
    "        interval = np.mean(np.array([np.abs(nanmean_result - np.nanpercentile (data, 5, axis=0)), np.abs(nanmean_result - np.nanpercentile (data, 95, axis=0))]))\n",
    "        \n",
    "        \n",
    "    elif type == 'bootstrap':\n",
    "        n_rows, n_cols = data.shape\n",
    "\n",
    "        # Initialize array to store bootstrap means\n",
    "        bootstrap_means = np.zeros((num_samples, n_cols))\n",
    "\n",
    "        # Perform bootstrap resampling for each column\n",
    "        for col in range(n_cols):\n",
    "            bootstrap_samples = np.random.choice(data[:, col][nan_mask[:, col]], size=(num_samples, n_rows), replace=True)\n",
    "            bootstrap_means[:, col] = np.mean(bootstrap_samples, axis=1)\n",
    "\n",
    "        # Calculate confidence interval bounds\n",
    "        ci_lower = np.percentile(bootstrap_means, 100 * (alpha / 2), axis=0)\n",
    "        ci_upper = np.percentile(bootstrap_means, 100 * (1 - alpha / 2), axis=0)\n",
    "        \n",
    "        interval = np.mean([abs(bootstrap_means - ci_lower), abs(bootstrap_means - ci_upper)], axis=0)\n",
    "        \n",
    "        interval = np.mean(interval, axis=0)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid 'type' argument. Use either 'sem' or 'bootstrap'.\")\n",
    "    \n",
    "    return nanmean_result, interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the files in the directory\n",
    "datadir = 'C:/Users/thome/Documents/PYTHON/Self-Control/raw_data/'\n",
    "data_files = glob.glob(os.path.join(datadir, '*.h5'))\n",
    "file_names = [os.path.basename(file) for file in data_files]\n",
    "\n",
    "save_dir = 'C:/Users/thome/Documents/PYTHON/Self-Control/single_neuron_summary/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D20231214_Rec04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [29:29<00:00,  3.81s/it]\n",
      "100%|██████████| 465/465 [03:37<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:10<00:00, 45.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:10<00:00, 46.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:10<00:00, 44.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "D20231219_Rec05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 787/787 [19:00<00:00,  1.45s/it]\n",
      "100%|██████████| 787/787 [05:45<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 134/787 [00:02<00:13, 48.78it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 787/787 [00:16<00:00, 48.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 195/787 [00:03<00:11, 49.67it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 787/787 [00:16<00:00, 49.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 91/787 [00:01<00:14, 48.94it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 787/787 [00:16<00:00, 48.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "D20231221_Rec06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606/606 [16:51<00:00,  1.67s/it]\n",
      "100%|██████████| 606/606 [04:36<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606/606 [00:13<00:00, 46.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 35/606 [00:00<00:12, 47.30it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 606/606 [00:12<00:00, 47.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 174/606 [00:03<00:09, 44.98it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 606/606 [00:13<00:00, 45.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "D20231224_Rec07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [13:57<00:00,  1.67s/it]\n",
      "100%|██████████| 503/503 [03:46<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [00:10<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [00:10<00:00, 47.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503/503 [00:10<00:00, 46.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "D20231227_Rec08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 546/546 [16:58<00:00,  1.87s/it]\n",
      "100%|██████████| 546/546 [03:51<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 82/546 [00:01<00:09, 50.50it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 546/546 [00:10<00:00, 50.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 80/546 [00:01<00:09, 50.62it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 546/546 [00:10<00:00, 50.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 516/546 [00:10<00:00, 48.54it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 546/546 [00:11<00:00, 49.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "K20240628_Rec04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 647/647 [16:34<00:00,  1.54s/it]\n",
      "100%|██████████| 647/647 [04:46<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 647/647 [00:13<00:00, 47.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 647/647 [00:13<00:00, 48.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 565/647 [00:12<00:01, 45.77it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 647/647 [00:13<00:00, 46.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "K20240701_Rec05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 538/538 [13:58<00:00,  1.56s/it]\n",
      "100%|██████████| 538/538 [03:59<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 90/538 [00:01<00:09, 46.12it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 538/538 [00:11<00:00, 46.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 90/538 [00:01<00:09, 48.23it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 538/538 [00:11<00:00, 48.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 89/538 [00:01<00:09, 45.28it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 538/538 [00:11<00:00, 45.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "K20240707_Rec06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [14:58<00:00,  1.61s/it]\n",
      "100%|██████████| 557/557 [04:10<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:11<00:00, 46.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 140/557 [00:02<00:08, 48.27it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 557/557 [00:11<00:00, 48.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:12<00:00, 45.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "K20240710_Rec07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 930/930 [25:34<00:00,  1.65s/it]\n",
      "100%|██████████| 930/930 [07:01<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 75/930 [00:01<00:18, 46.19it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 930/930 [00:20<00:00, 45.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 180/930 [00:03<00:16, 46.55it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 930/930 [00:19<00:00, 47.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 75/930 [00:01<00:18, 45.69it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 930/930 [00:20<00:00, 45.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "K20240712_Rec08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [13:14<00:00,  1.53s/it]\n",
      "100%|██████████| 520/520 [03:51<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 335/520 [00:07<00:03, 47.26it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 520/520 [00:11<00:00, 46.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 340/520 [00:06<00:03, 48.63it/s]C:\\Users\\thome\\AppData\\Roaming\\Python\\Python311\\site-packages\\pingouin\\regression.py:444: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  r2 = 1 - ss_res / ss_wtot\n",
      "100%|██████████| 520/520 [00:10<00:00, 48.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [00:11<00:00, 46.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "K20240715_Rec09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606/606 [16:22<00:00,  1.62s/it]\n",
      "100%|██████████| 606/606 [04:27<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606/606 [00:13<00:00, 46.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606/606 [00:12<00:00, 48.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606/606 [00:13<00:00, 45.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "K20240719_Rec11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 603/603 [15:11<00:00,  1.51s/it]\n",
      "100%|██████████| 603/603 [04:28<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 603/603 [00:12<00:00, 46.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 603/603 [00:12<00:00, 48.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running State 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 603/603 [00:12<00:00, 47.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Data saved \n",
      "\n",
      "All files processed :]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loop over each file\n",
    "for f_ix, file_path in enumerate(data_files):\n",
    "    \n",
    "    print(file_names[f_ix][0:-3]) \n",
    "\n",
    "    # access the data for this session\n",
    "    firing_rates = np.concatenate([pull_from_h5(file_path, 'CdN_zFR'), \n",
    "                                pull_from_h5(file_path, 'OFC_zFR')], axis=2)\n",
    "\n",
    "    u_names = np.concatenate([pull_from_h5(file_path, 'CdN_u_names'), \n",
    "                            pull_from_h5(file_path, 'OFC_u_names')], axis=0)\n",
    "\n",
    "    n_OFC = pull_from_h5(file_path, 'OFC_zFR').shape[2]\n",
    "    n_CdN = pull_from_h5(file_path, 'CdN_zFR').shape[2]\n",
    "    brain_areas = np.concatenate([np.zeros(shape=n_CdN, ), np.ones(shape=n_OFC, )]).astype(int)\n",
    "\n",
    "    ts = pull_from_h5(file_path, 'ts')\n",
    "    bhv = pd.read_hdf(file_path, key='bhv')\n",
    "\n",
    "    if len(bhv) > len(firing_rates):\n",
    "        bhv = bhv.loc[0 :len(firing_rates)-1]\n",
    "\n",
    "    # subselect trials with a response that was correct\n",
    "    trials2keep = (bhv['n_sacc'] > 0)\n",
    "    bhv = bhv.loc[trials2keep]\n",
    "    firing_rates = firing_rates[trials2keep, :,:]\n",
    "    firing_rates = np.nan_to_num(firing_rates, nan=0)\n",
    "\n",
    "    n_trials, n_times, n_units = np.shape(firing_rates)\n",
    "    \n",
    "    # get firing rates during choice epoch\n",
    "    choice_on = np.argwhere(ts == 0)[0][0]\n",
    "    choice_off = np.argwhere(ts ==300)[0][0]\n",
    "\n",
    "    cue_on = np.argwhere(ts == -500)[0][0]\n",
    "    cue_off = np.argwhere(ts == -100)[0][0]\n",
    "\n",
    "    choice_frs = np.mean(firing_rates[:,choice_on:choice_off,:], axis=1)\n",
    "    cue_frs = np.mean(firing_rates[:,cue_on:cue_off,:], axis=1)\n",
    "\n",
    "    ix = (bhv['n_sacc'] ==1)\n",
    "    n_units = np.size(choice_frs, 1)\n",
    "\n",
    "    # create indices for the states of each trial\n",
    "    s1_ix = bhv['state'] == 1\n",
    "    s2_ix = bhv['state'] == 2\n",
    "    s3_ix = bhv['state'] == 3\n",
    "\n",
    "    n_times = len(ts)\n",
    "\n",
    "    # initialize an array to accumulate p values into\n",
    "    choice_pvals = np.zeros((n_units, 3))\n",
    "    cue_pvals = np.zeros((n_units, 3))\n",
    "    t_factor_pvals = np.zeros((n_units, n_times, 5))\n",
    "\n",
    "    reg_betas = np.zeros((n_units, 3))\n",
    "    reg_pvals = np.zeros((n_units, 3))\n",
    "\n",
    "\n",
    "    # initialize array for accumulating condition mean firing rates into\n",
    "    f_cond_means = np.zeros((12, n_units))\n",
    "\n",
    "    # initialize a dataframe for running an anova\n",
    "    anova_df = pd.DataFrame()\n",
    "    anova_df['state'] = bhv['state'].loc[ix]\n",
    "    anova_df['val'] = bhv['ch_val'].loc[ix]\n",
    "\n",
    "    t_anova_df = pd.DataFrame()\n",
    "    t_anova_df['state'] = bhv['state']\n",
    "    t_anova_df['cue'] = bhv['state_cue']\n",
    "    t_anova_df['val'] = bhv['ch_val']\n",
    "\n",
    "    # loop over the neurons\n",
    "    for u in tqdm(range(n_units)):\n",
    "        \n",
    "        # add the firing rates to the anova\n",
    "        anova_df['choice_fr'] = choice_frs[ix, u]\n",
    "        anova_df['cue_fr'] = cue_frs[ix, u]\n",
    "        \n",
    "        # run the choice anova\n",
    "        choice_anova_mdl = pg.anova(dv='choice_fr', between=['state', 'val'], data=anova_df)\n",
    "        choice_pvals[u,:] = choice_anova_mdl['p-unc'].values[0:3]\n",
    "        \n",
    "        # run the cue anova\n",
    "        cue_anova_mdl = pg.anova(dv='cue_fr', between=['state', 'val'], data=anova_df)\n",
    "        cue_pvals[u,:] = cue_anova_mdl['p-unc'].values[0:3]\n",
    "            \n",
    "        # run value-in-state regressions\n",
    "        state1_reg = pg.linear_regression(anova_df['val'].loc[ix & s1_ix], anova_df['choice_fr'].loc[ix & s1_ix])\n",
    "        reg_pvals[u, 0] = state1_reg['pval'].values[1]\n",
    "        reg_betas[u, 0] = state1_reg['coef'].values[1]\n",
    "        \n",
    "        state2_reg = pg.linear_regression(anova_df['val'].loc[ix & s2_ix], anova_df['choice_fr'].loc[ix & s2_ix])\n",
    "        reg_pvals[u, 1] = state2_reg['pval'].values[1]\n",
    "        reg_betas[u, 1] = state2_reg['coef'].values[1]\n",
    "        \n",
    "        state3_reg = pg.linear_regression(anova_df['val'].loc[ix & s3_ix], anova_df['choice_fr'].loc[ix & s3_ix])\n",
    "        reg_pvals[u, 2] = state3_reg['pval'].values[1]\n",
    "        reg_betas[u, 2] = state3_reg['coef'].values[1]\n",
    "            \n",
    "        # fit the anova at each point in time\n",
    "        for t in range(n_times):\n",
    "                    \n",
    "            # add the firing rate for this specific time\n",
    "            t_anova_df['fr'] = firing_rates[:, t, u]\n",
    "            \n",
    "            # run the anova\n",
    "            ts_anova_mdl = pg.anova(dv='fr', between=['state', 'val', 'cue'], data=t_anova_df)\n",
    "            \n",
    "            # pull out the p values\n",
    "            t_factor_pvals[u, t, :] = ts_anova_mdl['p-unc'].values[0:5]\n",
    "        \n",
    "            \n",
    "    # let's try to understand the state code better with an AUROC analysis\n",
    "\n",
    "    # initialize arrays to accumulate results into\n",
    "    auc_scores = np.zeros((n_units, n_times, 4))\n",
    "    shuffle_auc_scores = np.zeros((n_units, n_times, 4)) \n",
    "\n",
    "    # let's only look at the single-saccade trials for this\n",
    "    b_triasl2balance = bhv['n_sacc']==1\n",
    "\n",
    "    # pull a balanced set of trials\n",
    "    trials2use, leftover_ix = pull_balanced_train_set(b_triasl2balance, [bhv['state'].values, bhv['state_cue'].values])\n",
    "\n",
    "    # grab the firing rates and behavioral data associated with these trials\n",
    "    b_fr = firing_rates[trials2use, :, :]\n",
    "    b_state_label = bhv['state'].loc[trials2use]\n",
    "\n",
    "    # now loop over each neuron\n",
    "    for u in tqdm(range(n_units)):\n",
    "        \n",
    "        # loop over times\n",
    "        for t in range(n_times):\n",
    "            \n",
    "            # run one-vs-all AUC classifiers for each state\n",
    "            auc_scores[u, t, 0] = roc_auc_score(b_state_label == 1, b_fr[:,t,u])\n",
    "            auc_scores[u, t, 1] = roc_auc_score(b_state_label == 2, b_fr[:,t,u])\n",
    "            auc_scores[u, t, 2] = roc_auc_score(b_state_label == 3, b_fr[:,t,u])\n",
    "            \n",
    "            # also look just at the state 1 and 2 trials\n",
    "            auc_scores[u, t, 3] = roc_auc_score(b_state_label[b_state_label < 3] == 1, b_fr[b_state_label < 3,t,u])\n",
    "            \n",
    "            # run the shuffles\n",
    "            # shuffle the labels\n",
    "            shuff_b_labels = np.random.permutation(b_state_label)\n",
    "            \n",
    "            # run one-vs-all AUC classifiers for each state\n",
    "            shuffle_auc_scores[u, t, 0] = roc_auc_score(shuff_b_labels == 1, b_fr[:,t,u])\n",
    "            shuffle_auc_scores[u, t, 1] = roc_auc_score(shuff_b_labels == 2, b_fr[:,t,u])\n",
    "            shuffle_auc_scores[u, t, 2] = roc_auc_score(shuff_b_labels == 3, b_fr[:,t,u])\n",
    "            \n",
    "            # also look just at the state 1 and 2 trials\n",
    "            shuffle_auc_scores[u, t, 3] = roc_auc_score(shuff_b_labels[shuff_b_labels < 3] == 1, b_fr[shuff_b_labels < 3,t,u])            \n",
    "                              \n",
    "    # rectify the scores\n",
    "    auc_scores[auc_scores < .5] = 1 - auc_scores[auc_scores < .5]\n",
    "    shuffle_auc_scores[shuffle_auc_scores < .5] = 1 - shuffle_auc_scores[shuffle_auc_scores < .5]\n",
    "    \n",
    "    # now let's look at value coding aligned to gaze - look at it separately for each state\n",
    "\n",
    "    # find the times of the saccades\n",
    "    # get the indices (in terms of ts) of when the first and second saccdes were\n",
    "    sacc1_ts_ix = np.abs(bhv['sacc1_t'].values[:, np.newaxis] - ts).argmin(axis=1)\n",
    "    sacc1_ts_ix[sacc1_ts_ix>50] = 50\n",
    "    sacc2_ts_ix = np.abs(bhv['sacc2_t'].values[:, np.newaxis] - ts).argmin(axis=1)\n",
    "\n",
    "\n",
    "    # define an offset (in terms of ts) to enable pulling a window around neural activity on each trial\n",
    "    # Calculate the mean timestep difference\n",
    "    timestep = int(np.mean(np.diff(ts)))\n",
    "\n",
    "    # Define the range for sacc_offset\n",
    "    sacc_offset = np.arange(-400, 400, timestep)\n",
    "\n",
    "    # Convert sacc_offset to integer indices for indexing\n",
    "    sacc_offset_ix = (sacc_offset / timestep).astype(int)\n",
    "\n",
    "    # initialize timecourse array for single-saccade trials\n",
    "    # - n_units, n_times, n_states\n",
    "    sacc1_val_pvals = np.zeros((n_units, len(sacc_offset_ix), 3))\n",
    "    sacc1_val_betas = np.zeros((n_units, len(sacc_offset_ix), 3))\n",
    "\n",
    "    # initialize arrays for a fixed window analysis\n",
    "    # - n_units, n_states\n",
    "    sacc1_fixwin_pvals = np.zeros((n_units, 3))\n",
    "    sacc1_fixwin_betas = np.zeros((n_units, 3))\n",
    "\n",
    "    # Convert fix_win_offset to integer indices for indexing\n",
    "    fix_win_offset = np.arange(0, 400, timestep)\n",
    "    fix_win_offset_ix = (fix_win_offset / timestep).astype(int)\n",
    "\n",
    "\n",
    "    # loop over the states and find the single-saccades associated with this state\n",
    "    for s in range(3):\n",
    "        \n",
    "        print(f'Running State {s+1}...')\n",
    "        \n",
    "        # find the single-saccade trials associated with this state\n",
    "        # - provides trial numbers\n",
    "        state_single_sacc_ix = np.argwhere((bhv['state'] == s+1) & (bhv['n_sacc'] == 1) & (bhv['rt'] < 1001)).flatten()\n",
    "\n",
    "        state_df = pd.DataFrame()\n",
    "        state_df['val'] = bhv['ch_val'].iloc[state_single_sacc_ix]\n",
    "\n",
    "        # loop over the neurons\n",
    "        for u in tqdm(range(n_units)):\n",
    "            \n",
    "            # initialize an array for this neuron to accumulate firing rates into for single saccade trials\n",
    "            u_state_frs = np.zeros((len(state_single_sacc_ix), len(sacc_offset)))\n",
    "            u_state_fix_win_fr = np.zeros(len(state_single_sacc_ix), )\n",
    "\n",
    "            # loop over the relevant trials (state_single_sacc_ix is an array of trial numbers)\n",
    "            for t_ix in range(len(state_single_sacc_ix)):\n",
    "                \n",
    "                # get the trial number\n",
    "                t_num = state_single_sacc_ix[t_ix]\n",
    "                \n",
    "                # get the index of when the saccade happened on this trial\n",
    "                t_sacc_ix = sacc1_ts_ix[t_num]\n",
    "                \n",
    "                # fill out the firing rate array\n",
    "                u_state_frs[t_ix, :] = firing_rates[t_num, t_sacc_ix + sacc_offset_ix, u]\n",
    "                \n",
    "                # get mean over the fixed window for this trial\n",
    "                u_state_fix_win_fr[t_ix] = np.mean(firing_rates[t_num, t_sacc_ix + fix_win_offset_ix, u])\n",
    "\n",
    "            # now run a value regression for each timestep\n",
    "            for time_ix in range(len(sacc_offset)):\n",
    "                \n",
    "                # single saccade trials\n",
    "                state_df['fr'] = u_state_frs[:, time_ix]\n",
    "                \n",
    "                state_reg = pg.linear_regression(state_df['val'], state_df['fr'])\n",
    "                sacc1_val_pvals[u, time_ix, s] = state_reg['pval'].values[1]\n",
    "                sacc1_val_betas[u, time_ix, s] = state_reg['coef'].values[1]\n",
    "                \n",
    "                \n",
    "            # run a value regression for the fixed window\n",
    "            state_df['win_fr'] = u_state_fix_win_fr\n",
    "\n",
    "            fix_win_reg = pg.linear_regression(state_df['val'], state_df['win_fr'])\n",
    "            sacc1_fixwin_pvals[u, s] = fix_win_reg['pval'].values[1]\n",
    "            sacc1_fixwin_betas[u, s] = fix_win_reg['coef'].values[1]\n",
    "            \n",
    "            \n",
    "    # now save the file\n",
    "    print('Saving data...')\n",
    "    save_name = save_dir + file_names[f_ix][0:-3] + '_summary.h5'\n",
    "\n",
    "    # Open an HDF5 file in write mode ('w' or 'w-' to create or truncate the file)\n",
    "    with h5py.File(save_name, 'w') as file:\n",
    "        # Create datasets within the HDF5 file and write data\n",
    "        file.create_dataset('brain_area', data=brain_areas)  \n",
    "        file.create_dataset('ts', data=ts)  \n",
    "        file.create_dataset('t_factor_pvals', data=t_factor_pvals)  \n",
    "        file.create_dataset('valstate_pvals', data=reg_pvals)  \n",
    "        file.create_dataset('valstate_betas', data=reg_betas)  \n",
    "        file.create_dataset('state_auc_scores', data=auc_scores)\n",
    "        file.create_dataset('shuffle_auc_scores', data=shuffle_auc_scores)\n",
    "        file.create_dataset('sacc1_val_pvals', data=sacc1_val_pvals)\n",
    "        file.create_dataset('sacc1_val_betas', data=sacc1_val_betas)\n",
    "        file.create_dataset('sacc1_fixwin_pvals', data=sacc1_fixwin_pvals)  \n",
    "        file.create_dataset('sacc1_fixwin_betas', data=sacc1_fixwin_betas)  \n",
    "        file.create_dataset('sacc_offset_t', data=sacc_offset)\n",
    "        \n",
    "    print('Data saved \\n')\n",
    "\n",
    "print('All files processed :]')\n",
    "\n",
    "    \n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
