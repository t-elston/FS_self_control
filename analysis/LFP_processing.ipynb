{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFP analysis\n",
    " - Created December 3, 2024 by Thomas Elston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import h5_utilities_module as h5u\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, optimize\n",
    "from scipy.optimize import curve_fit\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import h5py\n",
    "from scipy.signal import detrend, butter, filtfilt, correlate, hilbert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_path_from_dir(base_folder, file_name):\n",
    "    \"\"\"\n",
    "    Search for a file within the specified directory and its subdirectories\n",
    "    by matching the given file name.\n",
    "\n",
    "    Args:\n",
    "    - base_folder (str): The directory path to start the search from.\n",
    "    - file_name (str): The specific file name or part of the file name to be matched.\n",
    "\n",
    "    Returns:\n",
    "    - str or None: The path to the first file found with the given name,\n",
    "      or None if no file is found.\n",
    "    \"\"\"\n",
    "    base_folder = Path(base_folder)\n",
    "    \n",
    "    # Iterate through all files and directories in the base_folder\n",
    "    for file in base_folder.glob('**/*'):\n",
    "        if file.is_file() and file_name in file.name:\n",
    "            return file.resolve()  # Return the path of the first file found with the given name\n",
    "    \n",
    "    # Print an error message if no file with the given name is found\n",
    "    print(f\"No '{file_name}' file found in the directory.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def coherogram(lfp1, lfp2, n_perseg, n_fft, n_overlap, fq_min, fq_max, fs):\n",
    "    \"\"\"Computes a coherogram for an LFP stream of arbitrary length using a Hamming window.\n",
    "\n",
    "    Inputs: \n",
    "        lfp1 (ndarray):  Datastream for one LFP channel\n",
    "        lfp2 (ndarray):  Datastream for a different LFP channel\n",
    "        n_perseg(int):   Window over which each piece of the coherogram is evaluated\n",
    "        n_fft (int):     Number of samples to compute the FFT over (typically n_perseg)\n",
    "        fq_min (int):    Minimum frequency coherence is computed at\n",
    "        fq_max (int):    Maximum frequency coherence is evaluated at\n",
    "        fs (int):        Sampling frequency (in Hz) of the LFP data (typically 1000 Hz)\n",
    "            \n",
    "    Returns:\n",
    "        ts (ndarray):    Timestamps of each element of the coherogram\n",
    "        coh (ndarray):   A n_frequencies x n_times array where each element describes the coherence between\n",
    "                         lfp1 and lfp2 at each timestep and frequency\n",
    "        z_coh (ndarray): Z-scored coherence (zscore applied to each frequency)\n",
    "        freqs (ndarray): Array detailing which frquencies define the rows of coh     \n",
    "    \"\"\"\n",
    "    \n",
    "    if n_overlap < 1:\n",
    "        n_overlap = int(n_overlap * n_perseg) # convert to number of segments if a fraction provided (noverlap <= 1)\n",
    "\n",
    "    # find out the times to compute coherence at   \n",
    "    ts = np.arange(0, lfp1.shape[0] + (n_perseg - n_overlap), n_perseg - n_overlap)\n",
    "\n",
    "    n_freqs = ((fq_max - fq_min) * n_perseg // 1000) + 1\n",
    "\n",
    "    # define the starts and stops of each window to assess coherence over\n",
    "    # first columns is starts, second is stops\n",
    "    win_details = np.zeros(shape=(len(ts), 2))\n",
    "\n",
    "    # loop over each timestep and find appropriate windows. Truncate windows at the \n",
    "    # very beginning and end of of the data stream\n",
    "    for i_t in range(len(ts)):\n",
    "\n",
    "        # make centered windows\n",
    "        win_details[i_t, 0] = ts[i_t] - np.floor((n_perseg/2)) # window starts\n",
    "        win_details[i_t, 1] = ts[i_t] + np.floor((n_perseg/2)) # window ends\n",
    "\n",
    "        # is the left border of the window before the start of the session?\n",
    "        if win_details[i_t, 0] < 0: \n",
    "            # then set the window start to zero\n",
    "            win_details[i_t, 0] = 0\n",
    "\n",
    "        # is the right border of the window longer than the end of the session?\n",
    "        if win_details[i_t, 1] > lfp1.shape[0]:\n",
    "            # then set the window end to the end of the session\n",
    "            win_details[i_t, 1] = lfp1.shape[0]\n",
    "\n",
    "    # be sure these are ints\n",
    "    win_details = win_details.astype(int)\n",
    "    \n",
    "    # run the coherence on the first window to see how many frequencies are obtained\n",
    "    freqs, test_coh = signal.coherence(lfp1[0:n_perseg], lfp1[0:n_perseg], 1000, nfft=1000)\n",
    "    \n",
    "    n_freqs = len(freqs)\n",
    "\n",
    "    # intialize an array to accumulate the coherence data into\n",
    "    coh = np.zeros(shape=(n_freqs, len(ts)))\n",
    "    coh[:] = np.nan\n",
    "\n",
    "    # loop over each timestep\n",
    "    for t in range(len(ts)):\n",
    "        _, coh[:, t] = signal.coherence(lfp1[win_details[t, 0]: win_details[t, 1]],\n",
    "                                           lfp2[win_details[t, 0]: win_details[t, 1]],\n",
    "                                           fs=fs, nfft = n_fft, window='hamming')\n",
    "\n",
    "    # select the frequency range defined by fq_min and fq_max\n",
    "    freqs2keep = (freqs >= fq_min) & (freqs <= fq_max)\n",
    "\n",
    "    # zscore the coherence\n",
    "    z_coh = np.zeros_like(coh)\n",
    "    for f in range(len(freqs)):\n",
    "        f_mean = np.nanmean(coh[f,:])\n",
    "        f_std = np.nanstd(coh[f,:])\n",
    "        z_coh[f,:] = (coh[f,:] - f_mean) / f_std\n",
    "\n",
    "\n",
    "\n",
    "    return ts, coh[freqs2keep,: ], z_coh[freqs2keep, :], freqs[freqs2keep]\n",
    "\n",
    "\n",
    "def detrend_psd(freqs, psd):\n",
    "    \"\"\"\n",
    "    Detrend the PSD by fitting and removing the aperiodic component using a second-order polynomial.\n",
    "\n",
    "    Parameters:\n",
    "    - freqs (array): Frequencies corresponding to the PSD.\n",
    "    - psd (array): PSD values from scipy.signal.welch().\n",
    "\n",
    "    Returns:\n",
    "    - freqs (array): Frequencies corresponding to the PSD.\n",
    "    - psd_detrended (array): Detrended PSD values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure positive frequencies and PSD values\n",
    "    freqs = np.array(freqs)\n",
    "    psd = np.array(psd)\n",
    "    valid_indices = (freqs > 0) & (psd > 0)\n",
    "    freqs = freqs[valid_indices]\n",
    "    psd = psd[valid_indices]\n",
    "\n",
    "    # Convert to log-log space\n",
    "    log_freqs = np.log10(freqs)\n",
    "    log_psd = np.log10(psd)\n",
    "\n",
    "    # Fit a second-order polynomial to log-log data\n",
    "    def poly2(x, a, b, c):\n",
    "        return a * x**2 + b * x + c\n",
    "\n",
    "    popt, _ = curve_fit(poly2, log_freqs, log_psd)\n",
    "\n",
    "    # Compute the aperiodic fit and detrend\n",
    "    log_fit = poly2(log_freqs, *popt)\n",
    "    log_psd_detrended = log_psd - log_fit\n",
    "\n",
    "    # Convert back to linear space\n",
    "    psd_detrended = 10 ** log_psd_detrended\n",
    "\n",
    "    return freqs, psd_detrended\n",
    "\n",
    "class AmplitudeCrossCorr:\n",
    "    def __init__(self, low_freq, high_freq, fs, max_lags):\n",
    "        self.low_freq = low_freq\n",
    "        self.high_freq = high_freq\n",
    "        self.fs = fs\n",
    "        self.max_lags = max_lags\n",
    "        \n",
    "    def _preprocess(self, signal):\n",
    "        \"\"\"Internal preprocessing of each signal.\"\"\"\n",
    "        # Detrend\n",
    "        signal = detrend(signal)\n",
    "        \n",
    "        # Z-score\n",
    "        signal = (signal - np.mean(signal)) / (np.std(signal) + 1e-10)\n",
    "        \n",
    "        # Bandpass filter\n",
    "        nyq = self.fs / 2\n",
    "        b, a = butter(3, [self.low_freq/nyq, self.high_freq/nyq], btype='band')\n",
    "        signal = filtfilt(b, a, signal)\n",
    "        \n",
    "        return signal\n",
    "        \n",
    "    def compute(self, lfp1, lfp2):\n",
    "        \"\"\"\n",
    "        Compute amplitude cross-correlation between two LFP signals.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lfp1, lfp2 : np.ndarray\n",
    "            LFP time series\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        lags : np.ndarray\n",
    "            Lag times in milliseconds\n",
    "        xcorr : np.ndarray\n",
    "            Cross-correlation values\n",
    "        \"\"\"\n",
    "        # Preprocess both signals\n",
    "        lfp1_proc = self._preprocess(lfp1)\n",
    "        lfp2_proc = self._preprocess(lfp2)\n",
    "        \n",
    "        # Get amplitude envelopes\n",
    "        amp1 = np.abs(hilbert(lfp1_proc))\n",
    "        amp2 = np.abs(hilbert(lfp2_proc))\n",
    "        \n",
    "        # Compute cross-correlation\n",
    "        xcorr = correlate(amp1, amp2, mode='same')\n",
    "        \n",
    "        # Normalize\n",
    "        n = len(xcorr)\n",
    "        auto1 = correlate(amp1, amp1, mode='same')[int(n/2)]\n",
    "        auto2 = correlate(amp2, amp2, mode='same')[int(n/2)]\n",
    "        xcorr = xcorr / np.sqrt(auto1 * auto2)\n",
    "        \n",
    "        # Create lag vector in milliseconds\n",
    "        lags = np.arange(-self.max_lags, self.max_lags + 1) * 1000/self.fs\n",
    "        \n",
    "        # Extract the requested lags\n",
    "        middle = len(xcorr) // 2\n",
    "        max_lag_samples = int(self.max_lags)\n",
    "        start = middle - max_lag_samples\n",
    "        end = middle + max_lag_samples + 1\n",
    "        xcorr = xcorr[start:end]\n",
    "        \n",
    "        return lags, xcorr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where are the data?\n",
    "data_dir = 'C:/Users/thome/Documents/PYTHON/OFC-CdN 3 state self control/files_for_decoder/'\n",
    "\n",
    "# where to save the data?\n",
    "save_dir = 'C:/Users/thome/Documents/PYTHON/OFC-CdN 3 state self control/lfp_PSDs_Coh/'\n",
    "\n",
    "# get their relevant paths\n",
    "data_files = h5u.find_h5_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D20231219_Rec05\n",
      "\n",
      "Z-scoring lfps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:33<00:00, 11.46it/s]\n",
      "100%|██████████| 385/385 [00:33<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing each channel PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [01:40<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing aperiodic (1/f) component of PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 2417.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial coherence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:32<00:00, 26.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial amplitude cross correlation...\n",
      "File processed. \n",
      "\n",
      "D20231221_Rec06\n",
      "\n",
      "Z-scoring lfps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:49<00:00,  7.75it/s]\n",
      "100%|██████████| 385/385 [00:49<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing each channel PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [02:25<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing aperiodic (1/f) component of PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 3080.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial coherence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1246/1246 [00:47<00:00, 26.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial amplitude cross correlation...\n",
      "File processed. \n",
      "\n",
      "D20231224_Rec07\n",
      "\n",
      "Z-scoring lfps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:49<00:00,  7.78it/s]\n",
      "100%|██████████| 385/385 [00:49<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing each channel PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [02:26<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing aperiodic (1/f) component of PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 2180.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial coherence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1242/1242 [00:48<00:00, 25.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial amplitude cross correlation...\n",
      "File processed. \n",
      "\n",
      "D20231227_Rec08\n",
      "\n",
      "Z-scoring lfps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:33<00:00, 11.41it/s]\n",
      "100%|██████████| 385/385 [00:34<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing each channel PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [01:41<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing aperiodic (1/f) component of PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 2947.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial coherence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 864/864 [00:25<00:00, 33.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial amplitude cross correlation...\n",
      "File processed. \n",
      "\n",
      "K20240707_Rec06\n",
      "\n",
      "Z-scoring lfps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:48<00:00,  8.00it/s]\n",
      "100%|██████████| 385/385 [00:48<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing each channel PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [02:23<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing aperiodic (1/f) component of PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 3043.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial coherence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1212/1212 [00:42<00:00, 28.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial amplitude cross correlation...\n",
      "File processed. \n",
      "\n",
      "K20240710_Rec07\n",
      "\n",
      "Z-scoring lfps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:47<00:00,  8.15it/s]\n",
      "100%|██████████| 385/385 [00:46<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing each channel PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [02:21<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing aperiodic (1/f) component of PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 3014.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial coherence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1197/1197 [00:45<00:00, 26.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial amplitude cross correlation...\n",
      "File processed. \n",
      "\n",
      "K20240712_Rec08\n",
      "\n",
      "Z-scoring lfps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:40<00:00,  9.43it/s]\n",
      "100%|██████████| 385/385 [00:40<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing each channel PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [02:02<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing aperiodic (1/f) component of PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 2981.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial coherence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:37<00:00, 27.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial amplitude cross correlation...\n",
      "File processed. \n",
      "\n",
      "K20240715_Rec09\n",
      "\n",
      "Z-scoring lfps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:47<00:00,  8.08it/s]\n",
      "100%|██████████| 385/385 [00:49<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing each channel PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [02:16<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing aperiodic (1/f) component of PSD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 3199.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial coherence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1206/1206 [00:42<00:00, 28.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing trial-by-trial amplitude cross correlation...\n",
      "File processed. \n",
      "\n",
      "All files complete :]\n"
     ]
    }
   ],
   "source": [
    "for this_file in data_files:\n",
    "\n",
    "    f_name = Path(this_file).stem\n",
    "    print(f_name)\n",
    "\n",
    "    if 'D' in Path(this_file).stem:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = 1\n",
    "\n",
    "    # load the data\n",
    "    bhv = pd.read_hdf(this_file, key='bhv')\n",
    "    ofc_lfp = np.clip(h5u.pull_from_h5(this_file, 'OFC_lfp'), -1e6, 1e6)\n",
    "    cdn_lfp = np.clip(h5u.pull_from_h5(this_file, 'CdN_lfp'), -1e6, 1e6)\n",
    "    lfp_ts = h5u.pull_from_h5(this_file, 'lfp_ts')\n",
    "\n",
    "    # zscore the lfp\n",
    "    z_ofc_lfp = np.zeros((len(bhv), len(lfp_ts), ofc_lfp.shape[2]), dtype='float16')\n",
    "    z_cdn_lfp = np.zeros((len(bhv), len(lfp_ts), cdn_lfp.shape[2]), dtype='float16')\n",
    "\n",
    "    print('\\nZ-scoring lfps...')\n",
    "    for ch in tqdm(range(ofc_lfp.shape[2])):\n",
    "\n",
    "        ofc_ch_mean = np.nanmean(ofc_lfp[:,:, ch])\n",
    "        ofc_ch_std = np.nanstd(ofc_lfp[:,:, ch])\n",
    "\n",
    "        z_ofc_lfp[:,:, ch] = (ofc_lfp[:,:, ch] - ofc_ch_mean) / ofc_ch_std\n",
    "\n",
    "    for ch in tqdm(range(cdn_lfp.shape[2])):\n",
    "        cdn_ch_mean = np.nanmean(cdn_lfp[:,:, ch])\n",
    "        cdn_ch_std = np.nanstd(cdn_lfp[:,:, ch])\n",
    "\n",
    "        z_cdn_lfp[:,:, ch] = (cdn_lfp[:,:, ch] - cdn_ch_mean) / cdn_ch_std\n",
    "\n",
    "    # delete the original LFP\n",
    "    del ofc_lfp\n",
    "    del cdn_lfp\n",
    "\n",
    "    # compute PSD across the probe\n",
    "    window = 'hamming'\n",
    "    fs = 1000\n",
    "    n_fft = fs\n",
    "    n_overlap = np.round(.5*n_fft)\n",
    "\n",
    "    ofc_pwr = np.zeros((len(bhv), 501, z_ofc_lfp.shape[2]-1))\n",
    "    cdn_pwr = np.zeros((len(bhv), 501, z_cdn_lfp.shape[2]-1))\n",
    "\n",
    "    print('\\nComputing each channel PSD...')\n",
    "    for ch in tqdm(range(ofc_pwr.shape[2])):\n",
    "        for t in range(len(bhv)):\n",
    "            fq, ofc_pwr[t,:, ch] = signal.welch(z_ofc_lfp[t,:,ch], fs=fs, noverlap=n_overlap, nfft = n_fft, nperseg=n_fft)\n",
    "            fq, cdn_pwr[t,:, ch] = signal.welch(z_cdn_lfp[t,:,ch], fs=fs, noverlap=n_overlap, nfft = n_fft, nperseg=n_fft)\n",
    "\n",
    "    # calculate the channel mean PSDs\n",
    "    ofc_ch_means = np.nanmean(ofc_pwr, axis=0).T\n",
    "    cdn_ch_means = np.nanmean(cdn_pwr, axis=0).T\n",
    "\n",
    "    # subtract the aperiodic component\n",
    "    ofc_fooof_psd = np.zeros_like(ofc_ch_means)\n",
    "    cdn_fooof_psd = np.zeros_like(cdn_ch_means)\n",
    "\n",
    "    print('\\nRemoving aperiodic (1/f) component of PSD...')\n",
    "    for ch in tqdm(range(ofc_ch_means.shape[0])):\n",
    "        freqs, ofc_fooof_psd[ch, :] = detrend_psd(fq+1, ofc_ch_means[ch, :])\n",
    "        _, cdn_fooof_psd[ch, :] = detrend_psd(fq+1, cdn_ch_means[ch, :])\n",
    "\n",
    "    # account for the frequency shift imposed earlier (to avoid a divide-by-zero error)\n",
    "    ofc_fooof_psd = np.roll(ofc_fooof_psd, -1, axis=1)\n",
    "    cdn_fooof_psd = np.roll(cdn_fooof_psd, -1, axis=1)\n",
    "\n",
    "    ofc_theta_pwr = np.mean(ofc_fooof_psd[:, 4:9], axis=1)\n",
    "    ofc_alpha_pwr = np.mean(ofc_fooof_psd[:, 11:20], axis=1)\n",
    "    cdn_theta_pwr = np.mean(cdn_fooof_psd[:, 4:9], axis=1)\n",
    "    cdn_alpha_pwr = np.mean(cdn_fooof_psd[:, 11:20], axis=1)\n",
    "\n",
    "    ##\n",
    "    # get the mean activity over the probe for the coherence analysis\n",
    "    ofc_data = np.mean(z_ofc_lfp[:,:,0:384], axis=2)\n",
    "    cdn_data = np.mean(z_cdn_lfp[:,:,0:384], axis=2)\n",
    "\n",
    "    # run a single trial to get shape of data\n",
    "    ts, test_coh, _, freqs2 = coherogram(ofc_data[0,:], cdn_data[0,:], 1000, 1000, .95, 1, 50, 1000)\n",
    "\n",
    "\n",
    "    # initialize arrays for the trialwise coherence\n",
    "    coh_trials = np.zeros(shape=(len(freqs2), len(ts), len(bhv)), dtype='float16')\n",
    "    coh_trials[:] = np.nan\n",
    "    z_coh_trials = np.zeros(shape=(len(freqs2), len(ts), len(bhv)), dtype='float16')\n",
    "    z_coh_trials[:] = np.nan\n",
    "\n",
    "    print('\\nComputing trial-by-trial coherence')\n",
    "    for t in tqdm(range(len(bhv))):\n",
    "\n",
    "        if not np.isnan(np.sum(ofc_data[t,:])):\n",
    "            ts, coh_trials[:,:,t], z_coh_trials[:,:,t], freqs = coherogram(ofc_data[t,:], cdn_data[t,:],\n",
    "                                                                            1000, 1000, .95, 1, 50, 1000)\n",
    "            \n",
    "    ts = ts - 1500    \n",
    "    t_start = np.argmin(np.abs(ts - -1000))\n",
    "    t_end = np.argmin(np.abs(ts - 1000))\n",
    "\n",
    "    # chop off the borders because that will blow the zscore\n",
    "    coh_trials = coh_trials[:,t_start:t_end,:]   \n",
    "    z_coh_trials = z_coh_trials[:,t_start:t_end,:]    \n",
    "    ts = ts[t_start:t_end]\n",
    "\n",
    "    # Run an amplitude cross-correlation analysis\n",
    "    print('\\nComputing trial-by-trial amplitude cross correlation...')\n",
    "    max_lag=100\n",
    "    xcorr = AmplitudeCrossCorr(low_freq=10, high_freq=20, fs=1000, max_lags=max_lag)\n",
    "\n",
    "    # Initialize lists to store results\n",
    "    xcorr_results = np.zeros((len(bhv), (2*max_lag) + 1))\n",
    "    xcorr_results[:] = np.nan\n",
    "    max_lags = np.zeros((len(bhv), ))\n",
    "    max_lags[:] = np.nan\n",
    "\n",
    "    # Your trial loop\n",
    "    for t in range(len(bhv)):\n",
    "        if np.any(np.isnan(ofc_data[t])) or np.any(np.isnan(cdn_data[t])):\n",
    "            continue\n",
    "            \n",
    "        # Compute for this trial\n",
    "        lags, corr = xcorr.compute(ofc_data[t,1500:2000 + (500*s)], cdn_data[t,1500:2000 + (500*s)])\n",
    "        xcorr_results[t, :] = corr\n",
    "        peak_idx = np.argmax(np.abs(corr))\n",
    "        max_lags[t] = lags[peak_idx]\n",
    "\n",
    "    # set to nans trials with no resolved lag\n",
    "    max_lags[max_lags == 0] = np.nan\n",
    "    max_lags[max_lags == -100] = np.nan\n",
    "\n",
    "    # save the data!\n",
    "    save_name = save_dir + f_name + '_psd_coh.h5'\n",
    "    \n",
    "    # Open an HDF5 file in write mode ('w' or 'w-' to create or truncate the file)\n",
    "    with h5py.File(save_name, 'w') as file:\n",
    "        # Create datasets within the HDF5 file and write data\n",
    "        file.create_dataset('ofc_psd', data=ofc_fooof_psd)  \n",
    "        file.create_dataset('cdn_psd', data=cdn_fooof_psd)  \n",
    "        file.create_dataset('coh_trials', data=coh_trials)  \n",
    "        file.create_dataset('z_coh_trials', data=z_coh_trials)  \n",
    "        file.create_dataset('coh_ts', data = ts)\n",
    "\n",
    "        file.create_dataset('amp_x_corr_lags', data = max_lags)\n",
    "        \n",
    "        # Save behavior to the HDF5 file\n",
    "        bhv.to_hdf(save_name, key='bhv', mode='a')\n",
    "\n",
    "    print('File processed. \\n')\n",
    "    \n",
    "print('All files complete :]')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
